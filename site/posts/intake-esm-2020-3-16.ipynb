{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pleased to announce the release of `intake-esm` version 2020.3.16. This is a new release with bug fixes and new features. Everyone is invited to give it a try, and make their thoughts, suggestions, feedback known! This blogpost outlines these changes. Full changelog is available [here](https://intake-esm.readthedocs.io/en/latest/changelog.html#intake-esm-v2020-03-16).\n",
    "\n",
    "\n",
    "On GitHub: https://github.com/NCAR/intake-esm\n",
    "\n",
    "Documentation: https://intake-esm.readthedocs.io/\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "## Installation\n",
    "\n",
    "`Intake-esm` can be installed from PyPI with pip:\n",
    "\n",
    "```bash\n",
    "python -m pip intall intake-esm --upgrade\n",
    "```\n",
    "\n",
    "It is also available from conda-forge channel for conda isntallations:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge intake-esm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features\n",
    "\n",
    "\n",
    "### Enhanced search: enforce query criteria via `require_all_on` argument\n",
    "\n",
    "By default `intake-esm`'s `search()` method returns entries that fulfill **any of the criteria** specified in the query. Today `intake-esm` can return entries that fulfill **all query criteria** when the user supplies the `require_all_on` argument. The `require_all_on` parameter can be **a dataframe column** or **a list of dataframe columns** across which all elements must satisfy the query criteria.\n",
    "\n",
    "The `require_all_on` argument is best explained with the following example.  Consider the `intake-esm` catalog for the CMIP6 data stored on Google Cloud Storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pangeo-cmip6-ESM Collection with 235624 entries:\n",
       "\t> 15 activity_id(s)\n",
       "\n",
       "\t> 32 institution_id(s)\n",
       "\n",
       "\t> 69 source_id(s)\n",
       "\n",
       "\t> 101 experiment_id(s)\n",
       "\n",
       "\t> 135 member_id(s)\n",
       "\n",
       "\t> 29 table_id(s)\n",
       "\n",
       "\t> 313 variable_id(s)\n",
       "\n",
       "\t> 10 grid_label(s)\n",
       "\n",
       "\t> 235624 zstore(s)\n",
       "\n",
       "\t> 60 dcpp_init_year(s)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open collection for CMIP6 data hosted on Google Storage\n",
    "import intake\n",
    "\n",
    "url = \"https://git.io/JvP9r\"\n",
    "col = intake.open_esm_datastore(url)\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a query for our collection that requests multiple `variable_ids` and multiple `experiment_ids` from the Omon `table_id`, all from 3 different `source_ids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our query\n",
    "\n",
    "query = dict(\n",
    "    variable_id=[\"thetao\", \"o2\"],\n",
    "    experiment_id=[\"historical\", \"ssp245\", \"ssp585\"],\n",
    "    table_id=[\"Omon\"],\n",
    "    source_id=[\"ACCESS-ESM1-5\", \"AWI-CM-1-1-MR\", \"FGOALS-f3-L\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this `query` to search for all assets in the collection that satisfy *any combination* of these requests (i.e., with `require_all_on=None`, which is the default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>table_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWI-CM-1-1-MR</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGOALS-f3-L</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_id  variable_id  table_id\n",
       "source_id                                          \n",
       "ACCESS-ESM1-5              3            2         1\n",
       "AWI-CM-1-1-MR              2            1         1\n",
       "FGOALS-f3-L                1            1         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_subset = col.search(**query)\n",
    "\n",
    "col_subset.df.groupby(\"source_id\")[\n",
    "    [\"experiment_id\", \"variable_id\", \"table_id\"]\n",
    "].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the search results above include `source_ids` for which we only have one of the two variables, and one or two of the three experiments.\n",
    "\n",
    "We can tell `intake-esm` to discard any `source_id` that doesn't have *both* variables `[\"thetao\", \"o2\"]` *and* all three experiments `[\"historical\", \"ssp245\", \"ssp585\"]` by passing `require_all_on=[\"source_id\"]` to the search method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's search for assets that fulfill our query with `require_all_on=[\"source_id\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>table_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_id  variable_id  table_id\n",
       "source_id                                          \n",
       "ACCESS-ESM1-5              3            2         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_subset = col.search(require_all_on=[\"source_id\"], **query)\n",
    "col_subset.df.groupby(\"source_id\")[\n",
    "    [\"experiment_id\", \"variable_id\", \"table_id\"]\n",
    "].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with the `require_all_on=[\"source_id\"]` option, the only `source_id` that was returned by our query was the `source_id` for which all of the variables and experiments were found.\n",
    "\n",
    "\n",
    "Thanks to [Julius Busecke](https://github.com/jbusecke) for proposing this feature and reviewing the implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single File Catalogs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earlier version of [esm collection spec](https://github.com/NCAR/esm-collection-spec) required that the `catalog_file` entry in the input JSON file point to a CSV file. In some cases, it is useful to embed the content that would otherwise be in the CSV file in the input JSON file, itself. To support this use case, a `catalog_dict` entry was added to the esm collection spec (see [NCAR/esm-collection-spec#15](https://github.com/NCAR/esm-collection-spec/pull/15))\n",
    "\n",
    "Example: \n",
    "\n",
    "\n",
    "`sample-collection.json`:\n",
    "```json\n",
    "{\n",
    "    \"esmcat_version\":\"0.1.0\",\n",
    "    \"id\":\"aws-cesm1-le\",\n",
    "    \"description\":\"This is an ESM collection for CESM1 Large Ensemble Zarr dataset publicly available on Amazon S3 (us-west-2 region)\",\n",
    "    \"catalog_file\": \"sample-catalog.csv\",\n",
    "    \"attributes\":[\n",
    "        { \"column_name\":\"component\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"frequency\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"experiment\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"variable\", \"vocabulary\": \"\"}\n",
    "        ],\n",
    "        \n",
    "    \"assets\":{ \"column_name\":\"path\", \"format\":\"zarr\"},\n",
    "    ...\n",
    " }\n",
    "\n",
    "```\n",
    "\n",
    "`sample-catalog.csv`:\n",
    "```\n",
    "component,frequency,experiment,variable,path\n",
    "atm,daily,20C,FLNS,s3://ncar-cesm-lens/atm/daily/cesmLE-20C-FLNS.zarr\n",
    "atm,daily,20C,FLNSC,s3://ncar-cesm-lens/atm/daily/cesmLE-20C-FLNSC.zarr\n",
    "```\n",
    "    \n",
    "    \n",
    "For the example above, we have both `sample-collection.json` and `sample-catalog.csv` files. We can put the content of the `sample-catalog.csv` in the `sample-collection.json` file as follows:\n",
    "    \n",
    "\n",
    "\n",
    "`sample-collection.json`:\n",
    "```json\n",
    "{\n",
    "    \"esmcat_version\":\"0.1.0\",\n",
    "    \"id\":\"aws-cesm1-le\",\n",
    "    \"description\":\"This is an ESM collection for CESM1 Large Ensemble Zarr dataset publicly available on Amazon S3 (us-west-2 region)\",\n",
    "    \"catalog_dict\":[\n",
    "        {\n",
    "            \"component\":\"atm\",\n",
    "            \"frequency\":\"daily\",\n",
    "            \"experiment\":\"20C\",\n",
    "            \"variable\":\"FLNS\",\n",
    "            \"path\":\"s3://ncar-cesm-lens/atm/daily/cesmLE-20C-FLNS.zarr\"\n",
    "        },\n",
    "        {\n",
    "            \"component\":\"atm\",\n",
    "            \"frequency\":\"daily\",\n",
    "            \"experiment\":\"20C\",\n",
    "            \"variable\":\"FLNSC\",\n",
    "            \"path\":\"s3://ncar-cesm-lens/atm/daily/cesmLE-20C-FLNSC.zarr\"\n",
    "        },\n",
    "       ...\n",
    "    ],\n",
    "  \"attributes\":[\n",
    "        { \"column_name\":\"component\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"frequency\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"experiment\", \"vocabulary\":\"\"},\n",
    "        { \"column_name\":\"variable\", \"vocabulary\": \"\"}\n",
    "        ],\n",
    "        \n",
    "    \"assets\":{ \"column_name\":\"path\", \"format\":\"zarr\"},\n",
    "    ...\n",
    "    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And you can now see that the `catalog_file` entry has been replaced with the appropriate `catalog_dict` entry. Now, we have to keep track of a single file (`sample-collection.json`) which `intake-esm` can parse: \n",
    " \n",
    "\n",
    "```python\n",
    "import intake\n",
    "col = intake.open_esm_datastore(\"sample-collection.json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to [Joe Hamman](https://github.com/jhamman) for proposing this feature and reviewing the implementation. Thanks to [Brian Bonnlander](https://github.com/bonnland) for implementing this feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative paths for catalog files\n",
    "\n",
    "Fetching and loading catalog files in earlier version of `intake-esm` required using absolute paths/urls for the catalog file (CSV). \n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "- `old_sample.json`: \n",
    "```json\n",
    "{\n",
    "  \"esmcat_version\": \"0.1.0\",\n",
    "  \"id\": \"campaign-cesm2-cmip6-timeseries\",\n",
    "  \"description\": \"ESM collection for the CESM2 raw output that went into CMIP6 data. Located in campaign storage, accessible via GLADE on casper\",\n",
    "  \"catalog_file\": \"/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/campaign-cesm2-cmip6-timeseries.csv.gz\",\n",
    "    ...\n",
    "}\n",
    "```\n",
    "    \n",
    "\n",
    "Today  the `catalog_file` can point to a full path or a path relative to the input JSON file path:\n",
    "\n",
    "\n",
    "- `new_sample.json`:\n",
    "```json\n",
    "{\n",
    "  \"esmcat_version\": \"0.1.0\",\n",
    "  \"id\": \"campaign-cesm2-cmip6-timeseries\",\n",
    "  \"description\": \"ESM collection for the CESM2 raw output that went into CMIP6 data. Located in campaign storage, accessible via GLADE on casper\",\n",
    "  \"catalog_file\": \"campaign-cesm2-cmip6-timeseries.csv.gz\",\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "The following people contributed to the [NCAR/intake-esm](https://github.com/NCAR/intake-esm), [NCAR/esm-collection-spec](https://github.com/NCAR/esm-collection-spec) repositories since `intake-esm` release `2019.12.13` on December 13th, 2019:\n",
    "\n",
    "\n",
    "- Anderson Banihirwe\n",
    "- Brian Bonnlander\n",
    "- Joe Hamman\n",
    "- Julius Busecke"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nikola": {
   "author": "Anderson Banihirwe",
   "category": "data-catalog",
   "date": "2020-03-18 09:00:00 UTC-06:00",
   "description": "",
   "link": "",
   "slug": "intake-esm-2020316",
   "tags": "intake,tooling",
   "title": "Intake-esm Release 2020.3.16",
   "type": "text"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
